{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## What is PyTorch?\n",
        "\n",
        "PyTorch is a system for executing dynamic computational graphs over Tensor objects that behave similarly as NumPy `ndarray`. It comes with a powerful **automatic differentiation engine** that removes the need for manual back-propagation.\n",
        "\n",
        "## Why?\n",
        "\n",
        "* Our code will now run on GPUs! Much faster training. When using a framework like PyTorch or TensorFlow you can harness the power of the GPU for your own custom neural network architectures without having to write CUDA code directly (which is beyond the scope of this class)."
      ],
      "metadata": {
        "id": "GZXrGAQzz2zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, the computational graph is built up as you execute the code, as opposed to TensorFlow where you define your graph and then run it.\n",
        "In PyTorch, you create your graph by running it."
      ],
      "metadata": {
        "id": "c590kQIV0MOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Tensors\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see [Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)). Tensors are also optimized for automatic differentiation (we’ll see more about that later in the Autograd section). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API."
      ],
      "metadata": {
        "id": "_W-Dib2z0ToD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dwySLxqHjBlq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing a Tensor\n",
        "\n",
        "Tensors can be initialized in various ways. Lets take a look at the four popular ways:"
      ],
      "metadata": {
        "id": "hDCOGc3k0iOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. With random or constant values:\n",
        "\n",
        "### 1a. Construct a matrix filled zeros and of dtype `long`:"
      ],
      "metadata": {
        "id": "BlUZ0lYh0pF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(5, 3, dtype = torch.long) # or torch.zeros((5, 3), dtype = torch.long)\n",
        "print(x)\n",
        "print(type(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PusS9vrn0et_",
        "outputId": "73a674a2-0473-476c-f705-65aba0443be1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.zeros` returns a tensor filled with the scalar value 0, with the shape defined by the variable argument `size`.\n",
        "\n",
        "You can get the shape of the tensor using `x.size()` or `x.shape`.\n",
        "\n",
        "**Note:** `torch.Size` is in fact a tuple, so it supports all tuple operations."
      ],
      "metadata": {
        "id": "H-Kcm8co1Dnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.size())\n",
        "print(x.shape)\n",
        "print(type(x.shape))\n",
        "a, b = x.shape\n",
        "print(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9DPFsPL0zAY",
        "outputId": "40de264a-7608-4d95-e131-285e2ec3259d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 3])\n",
            "<class 'torch.Size'>\n",
            "5 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b. Uninitialized matrix\n",
        "\n",
        "An uninitialized matrix is declared, but does not contain definite known values before it is used. When an uninitialized matrix is created, whatever values were in the allocated memory at the time will appear as the initial values.\n",
        "\n",
        "Construct a 5x3 matrix, uninitialized:"
      ],
      "metadata": {
        "id": "IfzOe5CV2BgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFxEXz_F1uCV",
        "outputId": "5191d0bc-17ac-4ec1-d6bb-f34e709bf47d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-5.6448e+18,  4.5801e-41, -5.6448e+18],\n",
            "        [ 4.5801e-41,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  1.8788e+31,  1.7220e+22],\n",
            "        [ 2.1715e-18,  1.3592e+22,  2.1124e+20]])\n",
            "torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c. Construct a randomly initialized matrix:"
      ],
      "metadata": {
        "id": "OJaWiRzO2OFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5, 3) # or x = torch.rand((5, 3))\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTUsw7r42KFW",
        "outputId": "28483de0-2304-40c1-e727-a7b56d83364e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0279, 0.3598, 0.4221],\n",
            "        [0.8735, 0.3325, 0.8817],\n",
            "        [0.9714, 0.2689, 0.0279],\n",
            "        [0.8448, 0.7483, 0.7711],\n",
            "        [0.5739, 0.6520, 0.1653]])\n",
            "torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1d. Identity Matrix"
      ],
      "metadata": {
        "id": "Gs_jtC-C2gPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.eye(5)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUVVaOM52WC0",
        "outputId": "7034ecaa-1fa4-409f-9ad8-3fe6eb00c03f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are some of the most poular ways of creating a tensor with random or constant values\n",
        "\n",
        "### 2. Construct a tensor directly from data:\n",
        "\n",
        "`torch.tensor(data, dtype=None, device=None, requires_grad=False pin_memory=False)` → Tensor\n",
        "\n",
        "Constructs a tensor with `data`."
      ],
      "metadata": {
        "id": "B9kol4Fa2oFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(x)\n",
        "print(x.size())\n",
        "print(type(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab1kY9iU2kN7",
        "outputId": "d1a8916f-2725-4a08-a00d-c1d5b6165ebd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.Size([2, 3])\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create a tensor based on an existing tensor.\n",
        "\n",
        "These methods will reuse properties of the input tensor, e.g. `dtype`, unless new values are provided by user"
      ],
      "metadata": {
        "id": "_aybgJOK281H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size\n",
        "\n",
        "# rand_like will inherit all the attributes from its argument's tensor.\n",
        "# This is true in general for any *_like() methods.\n",
        "# Some of the other useful methods are torch.ones_like() and torch.zeros_like().\n",
        "\n",
        "x_ones = torch.ones_like(x) # retains the properties of x\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54KHgCYd26lV",
        "outputId": "1342a8df-077d-4cef-a649-2eccf41c99b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-2.4393, -1.2357, -0.8650],\n",
            "        [ 1.1607,  1.7652,  2.0316],\n",
            "        [ 1.9713, -0.1562,  0.1154],\n",
            "        [ 1.3006,  0.6381,  0.8290],\n",
            "        [ 0.6763, -0.1623, -0.3528]])\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. From a NumPy array\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa - see [Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label))."
      ],
      "metadata": {
        "id": "e6sEECwD3K3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "\n",
        "np_array = np.array(data)\n",
        "\n",
        "x_np = torch.from_numpy(np_array)\n",
        "x_np_2 = torch.tensor(np_array)\n",
        "print(x_np, \"\\n\", x_np_2)\n",
        "print(type(x_np))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Utw3yMT3GsT",
        "outputId": "5401170d-c63d-4c59-ef13-84068ca160d1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attributes of a Tensor\n",
        "\n",
        "The important attributes of a Tensor are their shape, datatype, and the device on which they are stored."
      ],
      "metadata": {
        "id": "hCBx2gAR3Uvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor = torch.rand(3,4)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to(\"cuda\")\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY55Pv233RGa",
        "outputId": "40de03d7-5482-46e8-91f9-bd4dce2b99ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch supports several different data types for tensors, each of which can be specified using the `dtype` argument when creating a tensor. Here are some of the most commonly used data types:\n",
        "\n",
        "* `torch.float32`: 32-bit floating-point number (float)\n",
        "* `torch.float64`: 64-bit floating-point number (double)\n",
        "* `torch.float16`: 16-bit floating-point number (half-precision)\n",
        "* `torch.int8`: 8-bit integer (signed)\n",
        "* `torch.uint8`: 8-bit integer (unsigned)\n",
        "* `torch.int16`: 16-bit integer (signed)\n",
        "* `torch.int32`: 32-bit integer (signed)\n",
        "* `torch.int64`: 64-bit integer (signed)\n",
        "* `torch.bool`: boolean (True or False)"
      ],
      "metadata": {
        "id": "HBgsUh9u3o1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "print(a.dtype)\n",
        "\n",
        "a = torch.tensor([1.1, 2.1111, 3.2])\n",
        "print(a.dtype)\n",
        "\n",
        "a = torch.tensor([1, 2, 3], dtype=torch.float16)\n",
        "print(a.dtype)\n",
        "\n",
        "a = torch.tensor([1, 2, 3], dtype=torch.float64)\n",
        "print(a.dtype)\n",
        "\n",
        "a = torch.tensor([1, 2, 3], dtype=torch.int16)\n",
        "print(a.dtype)\n",
        "\n",
        "a = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
        "print(a.dtype)\n",
        "\n",
        "a = torch.tensor([1, 2, 3], dtype=torch.uint8)\n",
        "print(a.dtype)\n",
        "\n",
        "a = torch.tensor([1, 1, 0], dtype=torch.bool)\n",
        "print(a.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDkSkyal3d3t",
        "outputId": "9363ea10-86a9-4f5e-f6e3-86ed8dfd9c0b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n",
            "torch.float16\n",
            "torch.float64\n",
            "torch.int16\n",
            "torch.int32\n",
            "torch.uint8\n",
            "torch.bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Till now we have looked at what a Tensor is in PyTorch, its important attributes and the different ways to create it."
      ],
      "metadata": {
        "id": "I6KKkYFo4Lb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operations on Tensors\n",
        "\n",
        "Now let us look at various operations that can be done on a Tensor.\n",
        "\n",
        "### 1. Addition"
      ],
      "metadata": {
        "id": "7mGzA8Ji4US7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, 3)\n",
        "y = torch.ones(5, 3)\n",
        "\n",
        "print(x + y) # 1st way\n",
        "\n",
        "print(torch.add(x, y)) # 2nd way\n",
        "\n",
        "result = torch.empty(5, 3) # 3rd way. Can provide an output tensor to store results\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FujdDr7b35NZ",
        "outputId": "0b5e4e49-f3a9-4787-e75c-104b685b6e03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4th way. Adds 1 to y\n",
        "print(y.add(1)) # also an example of \"broadcasting\" in PyTorch\n",
        "\n",
        "# 5th way\n",
        "y.add_(x) # Adds in-place\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIdj5wlH5CgI",
        "outputId": "b22621aa-afce-4703-f1fa-0210d51489d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Any operation that mutates a tensor in-place is post-fixed with an `_`. For example:` x.copy_(y), x.t_(),` will change `x`."
      ],
      "metadata": {
        "id": "4oruZjrZ5XDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Matrix Multiplication, Transpose and Inverse is similar to NumPy with slight variations."
      ],
      "metadata": {
        "id": "RZMFISSG5bfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = torch.randn((5, 3))\n",
        "m2 = torch.randn((5, 3))\n",
        "print(m2.t() @ m1) # In NumPy this is equivalent to print(m2.T @ m1)\n",
        "print(torch.inverse(m2.t() @ m1)) # In NumPy this is equivalent to print(inv(m2.T @ m1))\n",
        "print((m2.t()).mm(m1)) # We can also use the mm() method to do matrix multiplications"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTVv37ZC5I0z",
        "outputId": "c9f04a51-cacc-48bf-dbc7-50de196721c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.1922,  2.8153, -0.9838],\n",
            "        [ 1.7691, -0.5464, -1.9391],\n",
            "        [ 3.3471, -1.1133, -0.6788]])\n",
            "tensor([[ 0.1650, -0.2775,  0.5535],\n",
            "        [ 0.4882, -0.4413,  0.5530],\n",
            "        [ 0.0130, -0.6445,  0.3491]])\n",
            "tensor([[-2.1922,  2.8153, -0.9838],\n",
            "        [ 1.7691, -0.5464, -1.9391],\n",
            "        [ 3.3471, -1.1133, -0.6788]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use standard NumPy-like indexing with all bells and whistles!"
      ],
      "metadata": {
        "id": "dbidvp8l5nt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(x.size())\n",
        "print(x[0]) # 1st row\n",
        "print(x[:, 0]) # 1st column\n",
        "print(x[..., -1]) # last column\n",
        "print(x[1, 2])\n",
        "print(x[1][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_DndvTe5gqz",
        "outputId": "8767baed-0e69-49f7-fcfb-d00e6198b7ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "torch.Size([5, 3])\n",
            "tensor([1., 1., 1.])\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Resizing: If you want to resize/reshape tensor, you can use `torch.view`:"
      ],
      "metadata": {
        "id": "N8cr63MU5wA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByDoaW8j5qjs",
        "outputId": "be88b4b9-21d3-4efa-ed6d-c121a38c785e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. If you have a one element tensor, use `.item()` to get the value as a Python number"
      ],
      "metadata": {
        "id": "Tor44BiY548j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())\n",
        "# temp = torch.rand(5, 3)\n",
        "# print(temp)\n",
        "# print(temp.item()) -> Throws this error : ValueError: only one element tensors can be converted to Python scalars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjvD6K8050eV",
        "outputId": "dcc65862-ebca-41a9-d110-e0af1aba6ad0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3449])\n",
            "0.34486258029937744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check out Later:** 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc., are described [here](https://pytorch.org/docs/torch).\n",
        "\n",
        "Some important ones which are definitely worth checking out are `squeeze()`, `unsqueeze()`, `max()`, `clamp()`, `cat()`, `stack()`.\n",
        "\n",
        "Each of these operations can be run on the GPU (at typically higher speeds than on a CPU). If you’re using Colab, allocate a GPU by going to Runtime > Change runtime type > GPU.\n",
        "\n",
        "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using `.to` method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!"
      ],
      "metadata": {
        "id": "8DCrobo86BUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Moving Tensor to GPU."
      ],
      "metadata": {
        "id": "9qTmuIPn6HDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(\"cuda\")"
      ],
      "metadata": {
        "id": "VanBdkE457Lb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A neater way of doing it\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.zeros(2, 2).to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP1MgR858G8Y",
        "outputId": "034d0ac0-6fc1-4984-b0bf-99afe12e1101"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** `dim` in PyTorch is similar to `axis` in NumPy."
      ],
      "metadata": {
        "id": "dr9f8JNp6bI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Converting a Torch Tensor to a NumPy Array and vice-versa"
      ],
      "metadata": {
        "id": "4loFqCkm6_t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "print(a.size())\n",
        "\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "\n",
        "# Notice how the numpy array's value change\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# the thing is ... a and b are stored in the same memory space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNPE9HpJ6S5C",
        "outputId": "12d694e6-19be-446b-f896-b904a0daf6d2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "torch.Size([5])\n",
            "[1. 1. 1. 1. 1.]\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting NumPy Array to Torch Tensor\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43QFSEdq7WYc",
        "outputId": "d32ebc70-6f24-4c55-f26a-37a83a0cfe9a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this the Part 1 of this notebook is completed.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AG3pWKTY7vU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: AUTOGRAD: Automatic Differentiation\n",
        "\n",
        "The PyTorch's `autograd` package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different."
      ],
      "metadata": {
        "id": "wUWU9LgL8PH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some Background\n",
        "\n",
        "We had seen three important attributes of a tensor before: (recall them)\n",
        "\n",
        "The two more important attributes are the `.requires_grad` and `.grad` attribute.\n",
        "\n",
        "`torch.Tensor` is the central class of the package. If you set its attribute `.requires_grad` as `True`, it starts to track all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute.\n",
        "\n",
        "To stop a tensor from tracking history, you can call `.detach()` to detach it from the computation history, and to prevent future computation from being tracked.\n",
        "\n",
        "To prevent tracking history (and using memory), you can also wrap the code block in `with torch.no_grad():`. This can be particularly helpful when evaluating a model because the model may have trainable parameters with `requires_grad=True`, but for which we don’t need the gradients.\n",
        "\n",
        "There’s one more class which is very important for autograd implementation - a `Function`.\n",
        "\n",
        "`Tensor` and `Function` are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a `.grad_fn` attribute that references a `Function` that has created the `Tensor` (except for Tensors created by the user - their `grad_fn is None`).\n",
        "\n",
        "If you want to compute the derivatives, you can call `.backward()` on a `Tensor`. If `Tensor` is a scalar (i.e. it holds one element data), you don’t need to specify any arguments to `backward()`, however if it has more elements, you need to specify a `gradient` argument that is a tensor of matching shape."
      ],
      "metadata": {
        "id": "l5U-TYRi8eGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2, 2, requires_grad = True)\n",
        "print(x.requires_grad)\n",
        "x.requires_grad_(False) # This sets the requires_grad attribute to True for the tensor test in place.\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUTXHeJ87RlG",
        "outputId": "4a96b568-acb2-4ec5-c54d-8944a174452d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can set the requires_grad attribute directly during the initialization itself\n",
        "\n",
        "x = torch.ones(2, 2, requires_grad = True)\n",
        "print(x)\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsrid-0M9Py6",
        "outputId": "b3329c3f-b990-4f49-8bc0-93cbf7efa76a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets do a tensor operation on `x`:"
      ],
      "metadata": {
        "id": "hFIXPf2y9tEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = x + 2\n",
        "print(y)\n",
        "print(y.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzUsYJ1-9dZO",
        "outputId": "534e57f8-d51c-414e-c468-55d649134b57"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that even though we didn't explicitly set the `requires_grad` attribute of `y` to `True` it automatically sets since it is a resultant Tensor from another Tensor whose `requires_grad` is `True`. This means the PyTorch tracks all the operations of a Tensor once you set the `requires_grad` to `True`.\n",
        "\n",
        "One other important attribute is `grad_fn`. It stores the operation which lead to its creation. Notice how PyTorch creates a chain of operations through this `grad_fn`."
      ],
      "metadata": {
        "id": "NMoaPeCi957c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77BKYDJ293NS",
        "outputId": "bd955da1-ce57-4551-bdec-778a2ff59fe1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7fde031f1090>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do more operations on `y`"
      ],
      "metadata": {
        "id": "Ap-iNQ1D-w7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = y * y * 3\n",
        "print(z.grad_fn)\n",
        "print(z.grad_fn.next_functions[0][0].next_functions[0][0])\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)\n",
        "\n",
        "print(y.requires_grad)\n",
        "print(z.requires_grad)\n",
        "print(out.requires_grad)\n",
        "# Notice that although we did not explicitly set the requires_grad attribute to\n",
        "# \"True\" for the Tensors y, z and out, it is automatically set to True."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXVl3-_S-sBg",
        "outputId": "3dc844af-a7a1-4fb5-f9c9-51ea0f5fac0a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<MulBackward0 object at 0x7fde031f3dc0>\n",
            "<AddBackward0 object at 0x7fde031f10c0>\n",
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradients\n",
        "\n",
        "Let’s backprop now. You can access the gradients of a Tensor (if it exists) using the `.grad` attribute."
      ],
      "metadata": {
        "id": "MhbGceaTAxiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad) # We haven't backpropagated yet. Hence, its None."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKDZA3fS_A_H",
        "outputId": "32a4e90d-a5fa-4150-fe15-5caf989d822d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropagating in PyTorch is as simple as calling the\n",
        "# `.backward()` method\n",
        "\n",
        "out.backward()"
      ],
      "metadata": {
        "id": "PB84IcnUBFJe"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will do the `d(out)/dx` operation and stores the resulting the gradient in the `.grad` attribute of `x`"
      ],
      "metadata": {
        "id": "2paRBdXPBP_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9r1FdhXBPb6",
        "outputId": "53313eac-aaa0-4948-d80d-b287db93e46d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result obtained can be verified as follows :\n",
        "\n",
        "![forward_prop](https://drive.google.com/uc?id=1Q0AiOmNZNlFTULPNswk-csiCAZe-CoK9)\n",
        "\n",
        "![backprop](https://drive.google.com/uc?id=1z1ynWdNc1FwAVhf565kaX39OIbV-Qmsi)"
      ],
      "metadata": {
        "id": "XvTToxg9D1J6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can zero the gradient buffer as follows:\n",
        "x.grad.data.zero_()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_rFNBoBBg-y",
        "outputId": "000c656e-679a-433a-bca9-be3cb6a5d351"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also stop autograd from tracking history on Tensors with `.requires_grad=True` either by wrapping the code block in `with torch.no_grad():`"
      ],
      "metadata": {
        "id": "ip43cWTmERLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.requires_grad) # True\n",
        "print((x ** 2).requires_grad) # True\n",
        "\n",
        "with torch.no_grad():\n",
        "    print(x.requires_grad) # True\n",
        "    print((x ** 2).requires_grad) # False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXVj9HBBByUY",
        "outputId": "e456f138-502a-4266-b155-f013aa9299b9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or by using `.detach()` to get a new Tensor with the same content but that does not require gradients:"
      ],
      "metadata": {
        "id": "0LecL1h3Ebzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.requires_grad)\n",
        "print(x.eq(y).all())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYV4cAbPETos",
        "outputId": "dc8d5afd-788a-482a-a8aa-f0e45dc5d4cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "True\n",
            "tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check out Later:**\n",
        "\n",
        "Documentation of `autograd.Function` can be found at https://pytorch.org/docs/stable/autograd.html#function"
      ],
      "metadata": {
        "id": "R_DlFNFfEh5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This concludes the first session on PyTorch.\n",
        "\n",
        "Thank you!"
      ],
      "metadata": {
        "id": "AWZuuC9gEn1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1. [Deep Learning with PyTorch: A 60 minute blitz, Soumith Chintala](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "\n",
        "2. [Automatic Differentiation Package - TORCH.AUTOGRAD](https://pytorch.org/docs/stable/autograd.html)\n",
        "\n",
        "3. [TORCH](https://pytorch.org/docs/stable/torch.html)\n",
        "\n",
        "4. [Stefan Otte: Deep Neural Networks with PyTorch | PyData Berlin 2018](https://www.youtube.com/watch?v=_H3aw6wkCv0&t=821s)\n",
        "\n",
        "5. [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)\n",
        "\n",
        "6. [Tensor Attributes](https://pytorch.org/docs/stable/tensor_attributes.html)\n",
        "\n",
        "7. [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)"
      ],
      "metadata": {
        "id": "Csr9VS3gEl81"
      }
    }
  ]
}